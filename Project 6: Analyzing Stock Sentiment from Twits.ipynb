{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 6: Analyzing Stock Sentiment from Twits\n",
    "## Instructions\n",
    "Each problem consists of a function to implement and instructions on how to implement the function.  The parts of the function that need to be implemented are marked with a `# TODO` comment.\n",
    "\n",
    "## Packages\n",
    "When you implement the functions, you'll only need to you use the packages you've used in the classroom, like [Pandas](https://pandas.pydata.org/) and [Numpy](http://www.numpy.org/). These packages will be imported for you. We recommend you don't add any import statements, otherwise the grader might not be able to run your code.\n",
    "\n",
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "When deciding the value of a company, it's important to follow the news. For example, a product recall or natural disaster in a company's product chain. You want to be able to turn this information into a signal. Currently, the best tool for the job is a Neural Network. \n",
    "\n",
    "For this project, you'll use posts from the social media site [StockTwits](https://en.wikipedia.org/wiki/StockTwits). The community on StockTwits is full of investors, traders, and entrepreneurs. Each message posted is called a Twit. This is similar to Twitter's version of a post, called a Tweet. You'll build a model around these twits that generate a sentiment score.\n",
    "\n",
    "We've collected a bunch of twits, then hand labeled the sentiment of each. To capture the degree of sentiment, we'll use a five-point scale: very negative, negative, neutral, positive, very positive. Each twit is labeled -2 to 2 in steps of 1, from very negative to very positive respectively. You'll build a sentiment analysis model that will learn to assign sentiment to twits on its own, using this labeled data.\n",
    "\n",
    "The first thing we should to do, is load the data.\n",
    "\n",
    "## Import Twits \n",
    "### Load Twits Data \n",
    "This JSON file contains a list of objects for each twit in the `'data'` field:\n",
    "\n",
    "```\n",
    "{'data':\n",
    "  {'message_body': 'Neutral twit body text here',\n",
    "   'sentiment': 0},\n",
    "  {'message_body': 'Happy twit body text here',\n",
    "   'sentiment': 1},\n",
    "   ...\n",
    "}\n",
    "```\n",
    "\n",
    "The fields represent the following:\n",
    "\n",
    "* `'message_body'`: The text of the twit.\n",
    "* `'sentiment'`: Sentiment score for the twit, ranges from -2 to 2 in steps of 1, with 0 being neutral.\n",
    "\n",
    "\n",
    "To see what the data look like by printing the first 10 twits from the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'message_body': '$FITB great buy at 26.00...ill wait', 'sentiment': 2, 'timestamp': '2018-07-01T00:00:09Z'}, {'message_body': '@StockTwits $MSFT', 'sentiment': 1, 'timestamp': '2018-07-01T00:00:42Z'}, {'message_body': '#STAAnalystAlert for $TDG : Jefferies Maintains with a rating of Hold setting target price at USD 350.00. Our own verdict is Buy  http://www.stocktargetadvisor.com/toprating', 'sentiment': 2, 'timestamp': '2018-07-01T00:01:24Z'}, {'message_body': '$AMD I heard there’s a guy who knows someone who thinks somebody knows something - on StockTwits.', 'sentiment': 1, 'timestamp': '2018-07-01T00:01:47Z'}, {'message_body': '$AMD reveal yourself!', 'sentiment': 0, 'timestamp': '2018-07-01T00:02:13Z'}, {'message_body': '$AAPL Why the drop? I warren Buffet taking out his position?', 'sentiment': 1, 'timestamp': '2018-07-01T00:03:10Z'}, {'message_body': '$BA bears have 1 reason on 06-29 to pay more attention https://dividendbot.com?s=BA', 'sentiment': -2, 'timestamp': '2018-07-01T00:04:09Z'}, {'message_body': '$BAC ok good we&#39;re not dropping in price over the weekend, lol', 'sentiment': 1, 'timestamp': '2018-07-01T00:04:17Z'}, {'message_body': '$AMAT - Daily Chart, we need to get back to above 50.', 'sentiment': 2, 'timestamp': '2018-07-01T00:08:01Z'}, {'message_body': '$GME 3% drop per week after spike... if no news in 3 months, back to 12s... if BO, then bingo... what is the odds?', 'sentiment': -2, 'timestamp': '2018-07-01T00:09:03Z'}]\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('..', '..', 'data', 'project_6_stocktwits', 'twits.json'), 'r') as f:\n",
    "    twits = json.load(f)\n",
    "\n",
    "print(twits['data'][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of Data\n",
    "Now let's look at the number of twits in dataset. Print the number of twits below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of twit is 1548010.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"print out the number of twits\"\"\"\n",
    "\n",
    "print(f\"The number of twit is {len(twits['data'])}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Message Body and Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [twit['message_body'] for twit in twits['data']]\n",
    "\n",
    "# Since the sentiment scores are discrete, we'll scale the sentiments to 0 to 4 for use in our network\n",
    "sentiments = [twit['sentiment'] + 2 for twit in twits['data']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "With our data in hand we need to preprocess our text. These twits are collected by filtering on ticker symbols where these are denoted with a leader $ symbol in the twit itself. For example,\n",
    "\n",
    "`{'message_body': 'RT @google Our annual look at the year in Google blogging (and beyond) http://t.co/sptHOAh8 $GOOG',\n",
    " 'sentiment': 0}`\n",
    "\n",
    "The ticker symbols don't provide information on the sentiment, and they are in every twit, so we should remove them. This twit also has the `@google` username, again not providing sentiment information, so we should also remove it. We also see a URL `http://t.co/sptHOAh8`. Let's remove these too.\n",
    "\n",
    "The easiest way to remove specific words or phrases is with regex using the `re` module. You can sub out specific patterns with a space:\n",
    "\n",
    "```python\n",
    "re.sub(pattern, ' ', text)\n",
    "```\n",
    "This will substitute a space with anywhere the pattern matches in the text. Later when we tokenize the text, we'll split appropriately on those spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모든 트윗에는 티커정보들이 있다. $로 시작.\n",
    "- 모든 트윗에는 티커정보들이 있는데 이는 감정분석에 도움이 되지 않음으로 제거한다.\n",
    "- url을 제거한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$FITB great buy at 26.00...ill wait\n",
      "@StockTwits $MSFT\n",
      "#STAAnalystAlert for $TDG : Jefferies Maintains with a rating of Hold setting target price at USD 350.00. Our own verdict is Buy  http://www.stocktargetadvisor.com/toprating\n",
      "$AMD I heard there’s a guy who knows someone who thinks somebody knows something - on StockTwits.\n",
      "$AMD reveal yourself!\n",
      "$AAPL Why the drop? I warren Buffet taking out his position?\n",
      "$BA bears have 1 reason on 06-29 to pay more attention https://dividendbot.com?s=BA\n",
      "$BAC ok good we&#39;re not dropping in price over the weekend, lol\n",
      "$AMAT - Daily Chart, we need to get back to above 50.\n",
      "$GME 3% drop per week after spike... if no news in 3 months, back to 12s... if BO, then bingo... what is the odds?\n"
     ]
    }
   ],
   "source": [
    "for t in messages[:10]:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "def preprocess(message):\n",
    "    \"\"\"\n",
    "    This function takes a string as input, then performs these operations: \n",
    "        - lowercase\n",
    "        - remove URLs\n",
    "        - remove ticker symbols \n",
    "        - removes punctuation\n",
    "        - tokenize by splitting the string on whitespace \n",
    "        - removes any single character tokens\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        message : The text message to be preprocessed.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        tokens: The preprocessed text into tokens.\n",
    "    \"\"\" \n",
    "    URL_PATTERN = \"(http|https)?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "    TICKER_PATTERN = r'(?P<ticker>\\$\\w*)\\b'\n",
    "    USERNAME_PATTERN = r'@\\w+'\n",
    "    NOT_LETTER_PATTERN = r'[\\W_]+' \n",
    "    \n",
    "    # Lowercase the twit message\n",
    "    text = message.lower()\n",
    "    \n",
    "    # Replace URLs with a space in the message\n",
    "    text = re.sub(URL_PATTERN, \" \", text)\n",
    "    \n",
    "    # Replace ticker symbols with a space. The ticker symbols are any stock symbol that starts with $.\n",
    "    text = re.sub(TICKER_PATTERN, \" \", text)\n",
    "    \n",
    "    # Replace StockTwits usernames with a space. The usernames are any word that starts with @.\n",
    "    text = re.sub(URL_PATTERN, \" \", text)\n",
    "\n",
    "    # Replace everything not a letter with a space\n",
    "    text = re.sub(NOT_LETTER_PATTERN, \" \", text)\n",
    "    \n",
    "    # Tokenize by splitting the string on whitespace into a list of words\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Lemmatize words using the WordNetLemmatizer. You can ignore any word that is not longer than one character.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    tokens = [ wnl.lemmatize(token) for token in tokens if len(token)>1]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess All the Twits \n",
    "Now we can preprocess each of the twits in our dataset. Apply the function `preprocess` to all the twit messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:$FITB great buy at 26.00...ill wait\n",
      ">>>>:['great', 'buy', 'at', '26', '00', 'ill', 'wait']\n",
      "-----------------------------------------\n",
      "original:@StockTwits $MSFT\n",
      ">>>>:['stocktwits']\n",
      "-----------------------------------------\n",
      "original:#STAAnalystAlert for $TDG : Jefferies Maintains with a rating of Hold setting target price at USD 350.00. Our own verdict is Buy  http://www.stocktargetadvisor.com/toprating\n",
      ">>>>:['staanalystalert', 'for', 'jefferies', 'maintains', 'with', 'rating', 'of', 'hold', 'setting', 'target', 'price', 'at', 'usd', '350', '00', 'our', 'own', 'verdict', 'is', 'buy']\n",
      "-----------------------------------------\n",
      "original:$AMD I heard there’s a guy who knows someone who thinks somebody knows something - on StockTwits.\n",
      ">>>>:['heard', 'there', 'guy', 'who', 'know', 'someone', 'who', 'think', 'somebody', 'know', 'something', 'on', 'stocktwits']\n",
      "-----------------------------------------\n",
      "original:$AMD reveal yourself!\n",
      ">>>>:['reveal', 'yourself']\n",
      "-----------------------------------------\n",
      "original:$AAPL Why the drop? I warren Buffet taking out his position?\n",
      ">>>>:['why', 'the', 'drop', 'warren', 'buffet', 'taking', 'out', 'his', 'position']\n",
      "-----------------------------------------\n",
      "original:$BA bears have 1 reason on 06-29 to pay more attention https://dividendbot.com?s=BA\n",
      ">>>>:['bear', 'have', 'reason', 'on', '06', '29', 'to', 'pay', 'more', 'attention']\n",
      "-----------------------------------------\n",
      "original:$BAC ok good we&#39;re not dropping in price over the weekend, lol\n",
      ">>>>:['ok', 'good', 'we', '39', 're', 'not', 'dropping', 'in', 'price', 'over', 'the', 'weekend', 'lol']\n",
      "-----------------------------------------\n",
      "original:$AMAT - Daily Chart, we need to get back to above 50.\n",
      ">>>>:['daily', 'chart', 'we', 'need', 'to', 'get', 'back', 'to', 'above', '50']\n",
      "-----------------------------------------\n",
      "original:$GME 3% drop per week after spike... if no news in 3 months, back to 12s... if BO, then bingo... what is the odds?\n",
      ">>>>:['drop', 'per', 'week', 'after', 'spike', 'if', 'no', 'news', 'in', 'month', 'back', 'to', '12', 'if', 'bo', 'then', 'bingo', 'what', 'is', 'the', 'odds']\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for m in messages[:10]:\n",
    "    print(f\"original:{m}\")\n",
    "    print(f\">>>>:{preprocess(m)}\")\n",
    "    print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Implement\n",
    "\n",
    "tokenized = [ preprocess(m) for m in messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words\n",
    "Now with all of our messages tokenized, we want to create a vocabulary and count up how often each word appears in our entire corpus. Use the [`Counter`](https://docs.python.org/3.1/library/collections.html#collections.Counter) function to count up all the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Create a vocabulary by using Bag of words\n",
    "\"\"\"\n",
    "\n",
    "bow = Counter()\n",
    "for one_sample in tokenized:\n",
    "    bow.update(one_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138351"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Words Appearing in Message\n",
    "With our vocabulary, now we'll remove some of the most common words such as 'the', 'and', 'it', etc. These words don't contribute to identifying sentiment and are really common, resulting in a lot of noise in our input. If we can filter these out, then our network should have an easier time learning.\n",
    "\n",
    "We also want to remove really rare words that show up in a only a few twits. **Here you'll want to divide the count of each word by the number of messages. Then remove words that only appear in some small fraction of the messages.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Noise제거를 위해서 cutoff 를 설정해서, 많이 등장하는단어와, 적게 등장하는 단어를 날린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1548010"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_messages = len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = { w:c/num_of_messages for w, c in bow.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'great': 0.011353931822145853,\n",
       " 'buy': 0.04915213726009522,\n",
       " 'at': 0.08935924186536262,\n",
       " '26': 0.009675002099469641,\n",
       " '00': 0.015291890879257886,\n",
       " 'ill': 0.0005684717798980627,\n",
       " 'wait': 0.007331993979367058,\n",
       " 'stocktwits': 0.0014922384222324145,\n",
       " 'staanalystalert': 0.00263047396334649,\n",
       " 'for': 0.17669524098681533,\n",
       " 'jefferies': 0.0006821661358776752,\n",
       " 'maintains': 0.0005833295650544894,\n",
       " 'with': 0.04448356276768238,\n",
       " 'rating': 0.009971511811939199,\n",
       " 'of': 0.13652883379306335,\n",
       " 'hold': 0.014299003236413201,\n",
       " 'setting': 0.002512257672754052,\n",
       " 'target': 0.01070406521921693,\n",
       " 'price': 0.02395462561611359,\n",
       " 'usd': 0.0018746648923456566,\n",
       " '350': 0.0012622657476372891,\n",
       " 'our': 0.007884961983449719,\n",
       " 'own': 0.005793244229688439,\n",
       " 'verdict': 0.002413421101930866,\n",
       " 'is': 0.18403304888211316,\n",
       " 'heard': 0.0008766093242291716,\n",
       " 'there': 0.016759581656449248,\n",
       " 'guy': 0.008676946531353157,\n",
       " 'who': 0.011553542935769148,\n",
       " 'know': 0.012876531805350094,\n",
       " 'someone': 0.00335398350139857,\n",
       " 'think': 0.015685945181232678,\n",
       " 'somebody': 0.0007105897248725784,\n",
       " 'something': 0.003881757869781203,\n",
       " 'on': 0.15610945665725673,\n",
       " 'reveal': 0.00012661416915911395,\n",
       " 'yourself': 0.0007797107253829109,\n",
       " 'why': 0.014021873243712896,\n",
       " 'the': 0.25777352859477654,\n",
       " 'drop': 0.011488943869871641,\n",
       " 'warren': 0.0006563265095186723,\n",
       " 'buffet': 0.0008397878566675926,\n",
       " 'taking': 0.004145968049302007,\n",
       " 'out': 0.03662379441993269,\n",
       " 'his': 0.004048423459796772,\n",
       " 'position': 0.007593620196251962,\n",
       " 'bear': 0.021683968449816217,\n",
       " 'have': 0.034212311289978745,\n",
       " 'reason': 0.005023869354849129,\n",
       " '06': 0.004996737747172176,\n",
       " '29': 0.00561882675176517,\n",
       " 'to': 0.24510888172557024,\n",
       " 'pay': 0.004910174998869516,\n",
       " 'more': 0.035756874955588144,\n",
       " 'attention': 0.002337194204171808,\n",
       " 'ok': 0.0029508853301981252,\n",
       " 'good': 0.0285540791080161,\n",
       " 'we': 0.04183177111258971,\n",
       " '39': 0.128478498200916,\n",
       " 're': 0.008518678819904264,\n",
       " 'not': 0.04412568394261019,\n",
       " 'dropping': 0.0014657528052144366,\n",
       " 'in': 0.1326044405397898,\n",
       " 'over': 0.021105806810033528,\n",
       " 'weekend': 0.0023003727366102287,\n",
       " 'lol': 0.019985013016711777,\n",
       " 'daily': 0.009065186917397175,\n",
       " 'chart': 0.010341018468872941,\n",
       " 'need': 0.013979883850879516,\n",
       " 'get': 0.03016194985820505,\n",
       " 'back': 0.027808605887558867,\n",
       " 'above': 0.011526411328092196,\n",
       " '50': 0.018654272259223132,\n",
       " 'per': 0.01069502134999128,\n",
       " 'week': 0.028335734265282523,\n",
       " 'after': 0.022218848715447576,\n",
       " 'spike': 0.001423763412381057,\n",
       " 'if': 0.03811280288887023,\n",
       " 'no': 0.026048927332510772,\n",
       " 'news': 0.01275120961750893,\n",
       " 'month': 0.010753160509299035,\n",
       " '12': 0.013519938501689265,\n",
       " 'bo': 0.0003456050025516631,\n",
       " 'then': 0.013547070109366219,\n",
       " 'bingo': 0.00011692430927448789,\n",
       " 'what': 0.05113532858314869,\n",
       " 'odds': 0.0002532283383182279,\n",
       " 'strong': 0.01111039334371225,\n",
       " 'short': 0.05599705428259508,\n",
       " 'ratio': 0.004949580429066996,\n",
       " '17': 0.012765421412006383,\n",
       " '2018': 0.04430914528975911,\n",
       " '15': 0.011977958798715771,\n",
       " 'and': 0.13468905239630236,\n",
       " 'float': 0.0030064405268699817,\n",
       " '42': 0.0033262059030626416,\n",
       " 'via': 0.015174320579324423,\n",
       " 'sunshineave': 0.0023275043442871814,\n",
       " 'squeezing': 0.00014728587024631624,\n",
       " 'perfect': 0.0012842294300424416,\n",
       " 'place': 0.001841073378078953,\n",
       " 'an': 0.014541895724187829,\n",
       " 'option': 0.013277692004573615,\n",
       " 'straddle': 0.001441851150832359,\n",
       " 'near': 0.00376160360721184,\n",
       " 'supporting': 0.00017893941253609472,\n",
       " 'trend': 0.005225418440449351,\n",
       " 'deepakm2013': 1.2919813179501424e-06,\n",
       " 'nytunes': 1.2919813179501424e-06,\n",
       " 'start': 0.005723477238519131,\n",
       " 'new': 0.02999011634291768,\n",
       " 'monday': 0.004769349035212951,\n",
       " 'expect': 0.006691817236322763,\n",
       " 'volume': 0.02823108377852856,\n",
       " 'across': 0.0005045187046595306,\n",
       " 'key': 0.01794562050632748,\n",
       " 'company': 0.014308047105638853,\n",
       " 'various': 5.4263215353905985e-05,\n",
       " 'sector': 0.003264190799801035,\n",
       " 'breakout': 0.004313279629976551,\n",
       " 'strategy': 0.0010503808114934658,\n",
       " 'current': 0.003996098216419791,\n",
       " 'portfolio': 0.001595596927668426,\n",
       " 'bull': 0.01759032564389119,\n",
       " 'catalyst': 0.0008294520061239915,\n",
       " 'continuing': 0.00022674272130025,\n",
       " 'this': 0.1315036724568963,\n",
       " 'uptrend': 0.0010904322323499202,\n",
       " 'pill': 0.00012661416915911395,\n",
       " 'pack': 0.0001214462438873134,\n",
       " 'amazon': 0.007100729323453983,\n",
       " 'prime': 0.001178932952629505,\n",
       " 'day': 0.04315605196348861,\n",
       " 'earnings': 0.034201975439435144,\n",
       " 'test': 0.0025988204210567116,\n",
       " 'break': 0.011045148287155767,\n",
       " '1763': 3.875943953850427e-05,\n",
       " 'soon': 0.01043404112376535,\n",
       " 'ha': 0.028607050342052055,\n",
       " 'moved': 0.00217569653942804,\n",
       " '21': 0.01053093972261161,\n",
       " 'check': 0.0035245250353679886,\n",
       " 'movement': 0.001851409228622554,\n",
       " 'peer': 0.0020529583142227764,\n",
       " 'mkm': 0.00010594246807191168,\n",
       " 'partner': 0.0007519331270469829,\n",
       " 'set': 0.003772585448414416,\n",
       " '91': 0.0015988268809633012,\n",
       " 'it': 0.12503149204462505,\n",
       " 'too': 0.012269300585913528,\n",
       " 'early': 0.0030807294526521145,\n",
       " 'tell': 0.0030045025548930565,\n",
       " 'going': 0.03101401153739317,\n",
       " 'happen': 0.00276419402975433,\n",
       " 'even': 0.010216342271690751,\n",
       " 'about': 0.01783257214100684,\n",
       " 'raisinf': 6.459906589750712e-07,\n",
       " 'output': 7.041298182828277e-05,\n",
       " 'still': 0.02275825091569176,\n",
       " 'so': 0.02965613917222757,\n",
       " 'many': 0.006109133661927248,\n",
       " '66': 0.0022848689607948267,\n",
       " 'financially': 0.0003682146756157906,\n",
       " 'healthy': 0.0011679511114269289,\n",
       " 'problem': 0.0017790582748173462,\n",
       " 'meeting': 0.0006466366496340463,\n",
       " 'obligation': 0.0004328137415132977,\n",
       " 'nke': 0.0004689892184159017,\n",
       " 'fa': 0.0075535687753955074,\n",
       " 'amp': 0.0319487600209301,\n",
       " '8832fee1': 0.00011757029993346297,\n",
       " 'd06b': 0.00011757029993346297,\n",
       " '46b5': 0.00011757029993346297,\n",
       " '827f': 0.00011757029993346297,\n",
       " '26246a5e29a8': 0.00011757029993346297,\n",
       " 'bullish': 0.01628607050342052,\n",
       " 'stock': 0.04877487871525378,\n",
       " 'watch': 0.009462471172666843,\n",
       " 'setup': 0.005238338253628853,\n",
       " 'timeframes': 2.519363570002778e-05,\n",
       " 'blog': 0.0003527108998003889,\n",
       " 'by': 0.034864115864884596,\n",
       " 'sssvenky': 6.459906589750712e-07,\n",
       " 'just': 0.047292976143564966,\n",
       " 'high': 0.018293809471515043,\n",
       " 'alert': 0.007890775899380495,\n",
       " 'next': 0.030342181252059095,\n",
       " 'gt': 0.00607618813831952,\n",
       " '40': 0.007363001530997862,\n",
       " 'breakdown': 0.0007131736875084786,\n",
       " 'much': 0.010720214985691307,\n",
       " 'better': 0.008904335243312382,\n",
       " 'than': 0.018815123933307924,\n",
       " 'industry': 0.005032267233415805,\n",
       " 'average': 0.006025154876260489,\n",
       " '71': 0.002269365184979425,\n",
       " 'fslr': 8.785472962060969e-05,\n",
       " 'b431cf47': 3.617547690260399e-05,\n",
       " 'ec7e': 3.617547690260399e-05,\n",
       " '4226': 4.26353834923547e-05,\n",
       " 'b864': 3.617547690260399e-05,\n",
       " '511b6081b3be': 3.617547690260399e-05,\n",
       " 'miss': 0.0045044928650331715,\n",
       " 'these': 0.009128494001976732,\n",
       " 'confirms': 0.0002655021608387543,\n",
       " 'you': 0.06092983895452872,\n",
       " 'will': 0.082819232433899,\n",
       " 'see': 0.02864322581895466,\n",
       " 'violent': 9.496062686933546e-05,\n",
       " 'move': 0.014553523556049379,\n",
       " 'downward': 0.0005368182376082842,\n",
       " 'my': 0.03317420430100581,\n",
       " 'base': 0.0009483142873754045,\n",
       " 'gap': 0.006306806803573621,\n",
       " '200': 0.0056646920885524,\n",
       " 'ma': 0.0022254378201691204,\n",
       " 'cabot': 6.847500985135755e-05,\n",
       " 'weekly': 0.00463046104353331,\n",
       " 'video': 0.0018191096956738006,\n",
       " 'quot': 0.02589970349028753,\n",
       " 'resilient': 8.850072027958475e-05,\n",
       " 'growth': 0.023322200760976998,\n",
       " 'when': 0.01940555939561114,\n",
       " 'wa': 0.03569292188034961,\n",
       " 'kid': 0.0010956001576217208,\n",
       " 'froend': 6.459906589750712e-07,\n",
       " 'told': 0.0024825421024411987,\n",
       " 'me': 0.016727282123500494,\n",
       " 'moon': 0.0014095516178836054,\n",
       " 'made': 0.005049062990549157,\n",
       " 'cheese': 7.493491644110826e-05,\n",
       " 'percent': 0.004054883366386522,\n",
       " '35': 0.004651778735279488,\n",
       " '28': 0.008186639621191077,\n",
       " '18': 0.019391993591772662,\n",
       " '20': 0.019725970762462776,\n",
       " 'rank': 0.003447652146949955,\n",
       " '20th': 0.00020154908560022223,\n",
       " 'percentile': 0.0009037409319061246,\n",
       " 'murph3232': 6.459906589750712e-07,\n",
       " 'thank': 0.0026634194869542185,\n",
       " 'don': 0.016438524298938637,\n",
       " 'feel': 0.0038681920659427264,\n",
       " 'or': 0.024213667870362596,\n",
       " 'do': 0.015900414080012405,\n",
       " 'well': 0.01069889729394513,\n",
       " 'they': 0.036406095567858086,\n",
       " 'already': 0.006237039812404313,\n",
       " 'during': 0.0016543820776351574,\n",
       " 'youtube': 0.0004560694052364003,\n",
       " 'interview': 0.0004024521805414694,\n",
       " 'mitch': 4.0051420856454416e-05,\n",
       " 'couldn': 0.0008087803050367892,\n",
       " 'remember': 0.003113028985600868,\n",
       " 'single': 0.0013992157673400043,\n",
       " 'movie': 0.0005678257892390876,\n",
       " 'he': 0.0074883237188390255,\n",
       " 'watched': 0.00025452031963617804,\n",
       " 'all': 0.038712282220399095,\n",
       " 'year': 0.02213680790175774,\n",
       " 'except': 0.0007306154353008056,\n",
       " 'star': 0.0015387497496786196,\n",
       " 'war': 0.003203467677857378,\n",
       " 'black': 0.0007855246413136866,\n",
       " 'panther': 1.7441747792326922e-05,\n",
       " 'clothes': 7.42889257821332e-05,\n",
       " 'downgrade': 0.002748690253938928,\n",
       " '38': 0.0032674207530959103,\n",
       " 'sale': 0.017479215250547478,\n",
       " 'interest': 0.007609123972067364,\n",
       " '43': 0.0031879639020419765,\n",
       " 'shortvolumes': 0.004301005807456024,\n",
       " 'return': 0.004573613865543504,\n",
       " 'equity': 0.0021169113894613082,\n",
       " '97': 0.0018061898824942991,\n",
       " 'e4a695e1': 1.0981841202576211e-05,\n",
       " 'f0f2': 1.0981841202576211e-05,\n",
       " '45d3': 1.0981841202576211e-05,\n",
       " 'b20c': 1.0981841202576211e-05,\n",
       " '84c2169e9553': 1.0981841202576211e-05,\n",
       " 'although': 0.001207356541624408,\n",
       " 'market': 0.0346955123028921,\n",
       " 'up': 0.07850401483194552,\n",
       " 'doing': 0.0035768502787449693,\n",
       " 'advanced': 0.0006408227337032706,\n",
       " '05': 0.004613665286399959,\n",
       " 'a': 0.02983443259410469,\n",
       " 'info': 0.0024728522425565727,\n",
       " 'july': 0.002001279061504771,\n",
       " 'be': 0.057650790369571256,\n",
       " 'most': 0.005319087086000736,\n",
       " '5x': 0.00028229791797210614,\n",
       " 'normal': 0.0010490888301755157,\n",
       " 'friday': 0.0072086097635028195,\n",
       " '154': 0.0001931512070335463,\n",
       " '810': 5.4263215353905985e-05,\n",
       " 'contract': 0.00920601288105374,\n",
       " 'call': 0.04370126807966357,\n",
       " 'put': 0.023840285269475004,\n",
       " '57': 0.0030833134152880148,\n",
       " 'third': 0.0010290631197472885,\n",
       " 'design': 0.0003934083113158184,\n",
       " 'win': 0.0037990710654323937,\n",
       " 'timing': 0.00042699982558252206,\n",
       " 'match': 0.0002642101795208041,\n",
       " 'probably': 0.0032674207530959103,\n",
       " 'arm': 0.00019767314164637179,\n",
       " '1d21bec34e96': 6.459906589750712e-07,\n",
       " 'alcohol': 4.651132744620513e-05,\n",
       " 'tobacco': 9.625260818728561e-05,\n",
       " 'firearm': 1.9379719769252136e-06,\n",
       " 'president': 0.0018391354061020279,\n",
       " 'trump': 0.0076259197292007155,\n",
       " 'tweet': 0.0009024489505881745,\n",
       " 'spoke': 0.00011111039334371225,\n",
       " 'king': 0.0008468937539163184,\n",
       " 'salman': 2.583962635900285e-06,\n",
       " 'saudi': 0.000489014928844129,\n",
       " 'arabia': 9.689859884626069e-05,\n",
       " 'explained': 7.42889257821332e-05,\n",
       " 'him': 0.0013507664679168739,\n",
       " 'that': 0.05792856635293054,\n",
       " 'because': 0.0050845924767927856,\n",
       " 'turmoil': 8.333279500778418e-05,\n",
       " 'today': 0.04925032784025943,\n",
       " 'insight': 0.005288725525028908,\n",
       " 'intc': 0.0014373292162195334,\n",
       " 'mama': 0.00010723444938986183,\n",
       " 'said': 0.006072312194365669,\n",
       " 'ice': 0.0002519363570002778,\n",
       " 'cream': 7.42889257821332e-05,\n",
       " 'finish': 0.0007538710990239081,\n",
       " 'due': 0.0023875814755718633,\n",
       " 'dil': 1.9379719769252136e-06,\n",
       " 'noticed': 0.000235786590525901,\n",
       " 'last': 0.02441392497464487,\n",
       " 'jedi': 0.00011498633729756268,\n",
       " 'stream': 0.0003914703393388932,\n",
       " 'love': 0.0066860033203919875,\n",
       " 'here': 0.048431857675338016,\n",
       " 'go': 0.034072777307640134,\n",
       " 'leave': 0.0008740253615932713,\n",
       " 'gpaisa': 3.5529486243628916e-05,\n",
       " 'view': 0.0033126400992241653,\n",
       " 'look': 0.020154262569363247,\n",
       " '5ema': 5.16792527180057e-06,\n",
       " 'held': 0.001815879742378925,\n",
       " '20ema': 6.395307523853205e-05,\n",
       " 'stochastics': 4.71573181051802e-05,\n",
       " 'turning': 0.0007538710990239081,\n",
       " 'spy': 0.0013798360475707522,\n",
       " 'qqq': 0.0004244158629466218,\n",
       " 'opposite': 0.0005658878172621624,\n",
       " 'forward': 0.0022060581003998684,\n",
       " 'pe': 0.0028598006472826403,\n",
       " '75': 0.004846221923630985,\n",
       " 'valuation': 0.0029185857972493716,\n",
       " 'can': 0.0285669989211956,\n",
       " 'described': 0.00022351276800537464,\n",
       " 'cheap': 0.005061336813069683,\n",
       " 'mu': 0.00617179475584783,\n",
       " '1852fbab': 0.000244830459751552,\n",
       " 'a521': 0.000244830459751552,\n",
       " '4084': 0.0002467684317284772,\n",
       " 'b2cf': 0.000244830459751552,\n",
       " '8f89daf57241': 0.000244830459751552,\n",
       " 'saber': 8.397878566675926e-06,\n",
       " 'capital': 0.0018850007428892579,\n",
       " 'presentation': 0.0004037441618594195,\n",
       " 'common': 0.0009263506049702521,\n",
       " 'denominator': 5.813915930775641e-06,\n",
       " 'tencent': 0.00010594246807191168,\n",
       " 'facebook': 0.005656940200644699,\n",
       " 'google': 0.002103345585622832,\n",
       " 'how': 0.015793825621281517,\n",
       " 'one': 0.01777766293499396,\n",
       " 'performing': 0.0005549059760595862,\n",
       " 'crude': 0.0003158894322388098,\n",
       " 'petroleum': 0.00016085167408479273,\n",
       " 'natural': 0.00033397717069011184,\n",
       " 'gas': 0.0009651100445087564,\n",
       " 'dnr': 0.0002913417871977571,\n",
       " '390f838e': 7.493491644110826e-05,\n",
       " 'f784': 7.493491644110826e-05,\n",
       " '423a': 7.493491644110826e-05,\n",
       " '8673': 7.493491644110826e-05,\n",
       " '94476a9ff4aa': 7.493491644110826e-05,\n",
       " 'pu': 3.165354228977849e-05,\n",
       " 'simply': 0.0004108500591081453,\n",
       " 'havent': 0.00013824200102066525,\n",
       " 'lost': 0.0029437794329493995,\n",
       " 'any': 0.009237666423343519,\n",
       " 'brown': 0.0001660195993565933,\n",
       " 'run': 0.010195024579944574,\n",
       " 'tech': 0.006397891486489105,\n",
       " 'mf': 0.00019896512296432194,\n",
       " 'are': 0.06553123041840815,\n",
       " 'educated': 7.364293512315812e-05,\n",
       " 'their': 0.0156491237136711,\n",
       " 'shit': 0.004142092105348156,\n",
       " 'every': 0.005673089967119076,\n",
       " 'former': 0.000281005936654156,\n",
       " 'global': 0.0016227285353453789,\n",
       " 'manufacturing': 0.00023449460920795084,\n",
       " 'pfizer': 0.0002926337685157073,\n",
       " 'independent': 0.00010077454280011111,\n",
       " 'director': 0.0035225870633910634,\n",
       " 'nat': 8.785472962060969e-05,\n",
       " 'ricciardi': 2.583962635900285e-06,\n",
       " 'may': 0.007063907855892404,\n",
       " 'safest': 9.883657082318589e-05,\n",
       " 'special': 0.00040503614317736965,\n",
       " 'limited': 0.0003572328344132144,\n",
       " 'offer': 0.0009857817455959587,\n",
       " 'june': 0.0008281600248060413,\n",
       " '14th': 6.007713128468163e-05,\n",
       " '30th': 0.0001298441224539893,\n",
       " 'tradenet': 3.2299532948753562e-06,\n",
       " 'offering': 0.00041601798437994585,\n",
       " 'discount': 0.0009399164088087286,\n",
       " 'intro': 3.165354228977849e-05,\n",
       " 'program': 0.000653096556223797,\n",
       " 'below': 0.007250599156336199,\n",
       " '30': 0.01672922009547742,\n",
       " 'financials': 0.0006382387710673704,\n",
       " 'summary': 0.00030167763774135824,\n",
       " 'jeff': 0.000444441573374849,\n",
       " 'gundlach': 2.648561701797792e-05,\n",
       " 'sohn': 1.4857785156426639e-05,\n",
       " 'long': 0.02104637566940782,\n",
       " 'thesis': 0.0006498666029289217,\n",
       " 'energy': 0.0018016679478814737,\n",
       " 'low': 0.01500184107337808,\n",
       " 'peg': 0.00035594085309526425,\n",
       " 'which': 0.005291309487664808,\n",
       " 'compensates': 0.00019121323505662109,\n",
       " 'indicates': 0.001279707495429616,\n",
       " 'rather': 0.0015297058804529687,\n",
       " 'hpq': 4.5219346128254986e-05,\n",
       " '87d9930a': 1.614976647437678e-05,\n",
       " '9d05': 1.614976647437678e-05,\n",
       " '4a11': 1.614976647437678e-05,\n",
       " '9ac9': 1.614976647437678e-05,\n",
       " 'e9954e349fe5': 1.614976647437678e-05,\n",
       " 'pres': 0.00022674272130025,\n",
       " 'coming': 0.012227311193080148,\n",
       " 'mrplanner': 1.2919813179501424e-06,\n",
       " 'seems': 0.003482535642534609,\n",
       " 'support': 0.010983133183894161,\n",
       " '25': 0.015837106995432847,\n",
       " 'under': 0.0058068100335269155,\n",
       " 'likely': 0.0023552819426231096,\n",
       " '53': 0.0030697476114495384,\n",
       " 'bullshit': 0.0005652418266031873,\n",
       " 'worthless': 0.000662140425449448,\n",
       " 'mean': 0.003981240431263364,\n",
       " 'fucking': 0.0015406877216555448,\n",
       " 'nothing': 0.004532916454028074,\n",
       " 'macau': 0.00018023139385404488,\n",
       " 'usa': 0.0006918559957623013,\n",
       " 'take': 0.011388815317730505,\n",
       " 'let': 0.01739523646488072,\n",
       " 'where': 0.008023849975129359,\n",
       " 'right': 0.012306122053475107,\n",
       " 'now': 0.03715286076963327,\n",
       " 'ugly': 0.0011899147938320813,\n",
       " 'without': 0.0015109721513426916,\n",
       " 'clear': 0.0016931415171736618,\n",
       " 'level': 0.006176316690460656,\n",
       " 'term': 0.01173442032028217,\n",
       " 'bearish': 0.0073907791293337894,\n",
       " 'll': 0.008490255230909361,\n",
       " 'previously': 0.00131459099101427,\n",
       " 'mo': 0.0005277743683826332,\n",
       " 'followed': 0.0006279029205237692,\n",
       " 'end': 0.010191794626649698,\n",
       " 'another': 0.009043869225650997,\n",
       " 'runup': 0.0001214462438873134,\n",
       " 'dropped': 0.0019089023972713355,\n",
       " '10': 0.052825240147027476,\n",
       " 'smart': 0.0021459809691151866,\n",
       " 'money': 0.01609873321231775,\n",
       " 'betting': 0.000552968004082661,\n",
       " 'deal': 0.004342995200289404,\n",
       " 'update': 0.013276400023255664,\n",
       " 'technical': 0.00730550836234908,\n",
       " 'bad': 0.008552270334170968,\n",
       " 'doe': 0.007217007642069496,\n",
       " 'present': 0.0015658813573555727,\n",
       " 'nice': 0.011205353970581585,\n",
       " 'opportunity': 0.003794549130819568,\n",
       " 'wynn': 0.0003882403860440178,\n",
       " '5f008ceb': 6.201510326160683e-05,\n",
       " '7e89': 6.201510326160683e-05,\n",
       " '4999': 6.52450565564822e-05,\n",
       " 'a2da': 6.201510326160683e-05,\n",
       " 'c893680bc755': 6.201510326160683e-05,\n",
       " 'completely': 0.0006569725001776475,\n",
       " 'scale': 0.0002467684317284772,\n",
       " 'time': 0.02544621804768703,\n",
       " 'gobble': 6.847500985135755e-05,\n",
       " 'play': 0.0059637857636578575,\n",
       " 'aka': 0.00021705286141562394,\n",
       " 'favorite': 0.000562011873308312,\n",
       " 'them': 0.007144010697605313,\n",
       " 'iddy': 6.459906589750712e-07,\n",
       " 'bitty': 6.4599065897507124e-06,\n",
       " 'kiddy': 2.131769174617735e-05,\n",
       " 'hand': 0.0024108371392949656,\n",
       " '77': 0.0022603213157537743,\n",
       " 'awesome': 0.0011924987564679815,\n",
       " 'concerned': 0.00034948094650551355,\n",
       " 'eow': 0.001361102318460475,\n",
       " 'might': 0.005753838799490959,\n",
       " 'wk': 0.0004670512464389765,\n",
       " 'throwback': 3.81134488795292e-05,\n",
       " 'u': 0.008584569867119722,\n",
       " 'advisor': 0.00014211794497451567,\n",
       " 'upgrade': 0.004417284126071537,\n",
       " 'shorties': 0.0005219604524518576,\n",
       " 'dreaming': 0.00015762172078991738,\n",
       " 'depression': 8.97927015975349e-05,\n",
       " 'somethin': 1.7441747792326922e-05,\n",
       " 'loll': 3.100755163080342e-05,\n",
       " 'updated': 0.000525836396405708,\n",
       " 'hormel': 7.42889257821332e-05,\n",
       " 'food': 0.0009625260818728562,\n",
       " 'dividend': 0.005470248900200903,\n",
       " 'analysis': 0.002211872016330644,\n",
       " 'consumer': 0.0012855214113603917,\n",
       " 'defensive': 0.00018216936583097007,\n",
       " 'intel': 0.005146607580054393,\n",
       " 'profitability': 0.0012189843734859594,\n",
       " 'safety': 0.0007273854820059302,\n",
       " 'score': 0.001713167227601889,\n",
       " 'technology': 0.002023242743909923,\n",
       " 'both': 0.004029043740027519,\n",
       " 'positive': 0.005839755557134643,\n",
       " 'looking': 0.011583258506082002,\n",
       " 'chk': 0.0007299694446418304,\n",
       " '4df21b39': 0.00011175638400268732,\n",
       " 'cb5c': 0.00011175638400268732,\n",
       " '41b6': 0.00011175638400268732,\n",
       " '88a7': 0.00011175638400268732,\n",
       " 'ddbd28711da9': 0.00011175638400268732,\n",
       " 'mad': 0.0008023203984470384,\n",
       " 'report': 0.03571488556275476,\n",
       " 'block': 0.006410165309009632,\n",
       " 'person': 0.0004509014799645997,\n",
       " 'spam': 0.00017570945924121937,\n",
       " 'should': 0.015521217563194037,\n",
       " 'open': 0.013366838715512174,\n",
       " 'projection': 0.0001841073378078953,\n",
       " 'thats': 0.0014586469079657107,\n",
       " 'true': 0.001377898075593827,\n",
       " 'prefer': 0.00023320262789000072,\n",
       " 'from': 0.04031692301729317,\n",
       " 'turd': 0.0006976699116930769,\n",
       " '89': 0.001804897901176349,\n",
       " 'wal': 8.074883237188391e-05,\n",
       " 'mart': 9.496062686933546e-05,\n",
       " 'aristocrat': 0.0001950891790104715,\n",
       " 'valueinvesting': 3.4237504925678774e-05,\n",
       " 'dvb': 1.4211794497451568e-05,\n",
       " 'aaamp': 1.8087738451301994e-05,\n",
       " 'marriage': 2.4547645041052707e-05,\n",
       " '2m': 0.0007855246413136866,\n",
       " 'bank': 0.004870769568672037,\n",
       " 'account': 0.0018081278544712243,\n",
       " 'dm': 3.617547690260399e-05,\n",
       " '60': 0.0061724407465068055,\n",
       " '52': 0.006183422587709382,\n",
       " 'won': 0.003501269371644886,\n",
       " 'stop': 0.00825834458433731,\n",
       " 'posting': 0.0008333279500778418,\n",
       " 'holding': 0.00956647566876183,\n",
       " 'big': 0.017881667431088946,\n",
       " 'calm': 0.0005859135276903896,\n",
       " 'down': 0.04479622224662631,\n",
       " 'luck': 0.002213809988307569,\n",
       " 'chase': 0.000879193286865072,\n",
       " 'continues': 0.0015762172078991738,\n",
       " 'hopefully': 0.0016912035451967366,\n",
       " 'catch': 0.0011304836532063747,\n",
       " 'before': 0.01668593872132609,\n",
       " 'lisa': 0.001986421276348344,\n",
       " 'announces': 0.0021802184740408654,\n",
       " '3rd': 0.0007777727534059857,\n",
       " 'bbby': 8.656274830265954e-05,\n",
       " 'f2bb9afa': 2.8423588994903135e-05,\n",
       " 'b79e': 2.8423588994903135e-05,\n",
       " '4ecc': 2.8423588994903135e-05,\n",
       " 'ace1': 2.8423588994903135e-05,\n",
       " '4be77006d5e1': 2.8423588994903135e-05,\n",
       " 'permamently': 6.459906589750712e-07,\n",
       " 'turned': 0.0008759633335701965,\n",
       " 'off': 0.013730531456515139,\n",
       " 'trading': 0.013681436166433034,\n",
       " 'maybe': 0.0050535849251619825,\n",
       " 'altogether': 1.679575713335185e-05,\n",
       " 'manipulation': 0.0016046407968940768,\n",
       " 'very': 0.012924981104773225,\n",
       " 'rich': 0.00104327491424474,\n",
       " 'make': 0.012876531805350094,\n",
       " 'poor': 0.0012222143267808347,\n",
       " 'fuk': 0.00014663987958734117,\n",
       " 'almost': 0.0036130257556475733,\n",
       " 'pct': 0.0004580073772133255,\n",
       " 'buyback': 0.003294552360772863,\n",
       " 'got': 0.010475384525939754,\n",
       " '4993': 6.459906589750712e-07,\n",
       " 'share': 0.03149979651294242,\n",
       " 'though': 0.002660189533659343,\n",
       " 'drip': 0.000208654982848948,\n",
       " '11': 0.017923656823922326,\n",
       " '017': 1.614976647437678e-05,\n",
       " '81': 0.0019728554725098675,\n",
       " '19': 0.012732475888398653,\n",
       " 'dumped': 0.0006866880704905007,\n",
       " 'obv': 0.00011627831861551283,\n",
       " 'but': 0.03456760615241503,\n",
       " 'jeez': 0.00021899083339254913,\n",
       " 'bit': 0.0028701364978262413,\n",
       " 'done': 0.0035419667831603154,\n",
       " 'bounce': 0.007503181503995452,\n",
       " 'heikin': 6.4599065897507124e-06,\n",
       " 'ashi': 7.751887907700854e-06,\n",
       " 'candle': 0.0021085135108946324,\n",
       " 'confirmation': 0.00047738709698257764,\n",
       " 'liking': 0.00027067008611055487,\n",
       " 'wife': 0.0004198939283337963,\n",
       " 'tree': 0.0003320391987131866,\n",
       " 'fiddy': 2.067170108720228e-05,\n",
       " 'sure': 0.005359138506857191,\n",
       " 'piggy': 0.00017441747792326922,\n",
       " 'lot': 0.006472180412271239,\n",
       " 'coin': 0.00026162621688490385,\n",
       " 'spend': 0.0005200224804749324,\n",
       " 'candy': 7.299694446418305e-05,\n",
       " '23': 0.008083281115755066,\n",
       " '76': 0.0019457238648329146,\n",
       " 'microsoft': 0.001279707495429616,\n",
       " 'investor': 0.005514176265011208,\n",
       " 'aren': 0.0010897862416909452,\n",
       " 'happy': 0.002813289319836435,\n",
       " 'royal': 0.00027906796467723076,\n",
       " 'canada': 0.000870149417639421,\n",
       " 'reiterates': 0.0008611055484137699,\n",
       " 'outperform': 0.001161491204837178,\n",
       " 'loop': 0.00018475332846687036,\n",
       " 'raise': 0.003728658083604111,\n",
       " '80': 0.005255134010762204,\n",
       " 'never': 0.005824251781319242,\n",
       " 'been': 0.012804826842203862,\n",
       " 'wrong': 0.0036227156155321993,\n",
       " 'miracle': 0.00020090309494124716,\n",
       " '8o': 6.459906589750712e-07,\n",
       " 'period': 0.0007499951550700576,\n",
       " 'bollinger': 0.000870149417639421,\n",
       " 'band': 0.000979321839006208,\n",
       " 'dare': 0.00022803470261820015,\n",
       " 'say': 0.01052318783470391,\n",
       " 'didn': 0.0038255566824503717,\n",
       " 'guilty': 6.266109392058191e-05,\n",
       " 'fudge': 4.26353834923547e-05,\n",
       " 'hardly': 0.00016472761803864317,\n",
       " 'ever': 0.0036156097182834736,\n",
       " 'informative': 2.131769174617735e-05,\n",
       " 'comment': 0.0013914638794323034,\n",
       " 'page': 0.00036433873166194015,\n",
       " 'broken': 0.0010284171290883134,\n",
       " 'giving': 0.0011485713916576767,\n",
       " 'endless': 0.00015051582354119159,\n",
       " 'buffering': 2.583962635900285e-06,\n",
       " 'icon': 6.136911260263177e-05,\n",
       " 'give': 0.0049573323169746965,\n",
       " 'viral': 1.1627831861551282e-05,\n",
       " 'walk': 0.0007215715660751546,\n",
       " 'away': 0.003102047144398292,\n",
       " 'highlight': 0.00016085167408479273,\n",
       " 'growing': 0.001442497141491334,\n",
       " 'democrat': 0.0001795854031950698,\n",
       " 'leaving': 0.0005633038546262621,\n",
       " 'party': 0.0011020600642114714,\n",
       " 'epoch': 1.2919813179501424e-06,\n",
       " 'robert': 0.0006285489111827443,\n",
       " 'baird': 0.00042053991899277136,\n",
       " 'neutral': 0.002249339474551198,\n",
       " 'weed': 0.00046317530248512605,\n",
       " 'other': 0.005472186872177829,\n",
       " 'drug': 0.0008481857352342685,\n",
       " 'guess': 0.003828786635745247,\n",
       " 'reasonable': 0.00039405430197479344,\n",
       " 'wba': 9.496062686933546e-05,\n",
       " 'd4067eb8': 3.165354228977849e-05,\n",
       " '9699': 3.294552360772863e-05,\n",
       " '411d': 3.165354228977849e-05,\n",
       " 'ab3c': 3.165354228977849e-05,\n",
       " '8591fd573a1a': 3.165354228977849e-05,\n",
       " 'nike': 0.0025975284397387615,\n",
       " 'winning': 0.0013617483091194502,\n",
       " 'click': 0.0005788076304416638,\n",
       " 'booking': 0.0005322963029954587,\n",
       " 'app': 0.0038436444209016736,\n",
       " 'native': 1.2919813179501425e-05,\n",
       " 'seamless': 6.4599065897507124e-06,\n",
       " 'lovalized': 6.459906589750712e-07,\n",
       " 'transactable': 6.459906589750712e-07,\n",
       " 'ap': 5.16792527180057e-05,\n",
       " 'vitiello': 6.459906589750712e-07,\n",
       " 'tapped': 8.139482303085897e-05,\n",
       " 'acting': 0.0004974128074108048,\n",
       " 'reach': 0.0012674336729090897,\n",
       " 'iconic': 4.069741151542949e-05,\n",
       " 'brand': 0.0012726015981808904,\n",
       " 'built': 0.00028811183390288177,\n",
       " 'mobile': 0.0006240269765699188,\n",
       " 'show': 0.006188590512981183,\n",
       " '13': 0.010200192505216374,\n",
       " '74': 0.001989005238984244,\n",
       " 'morning': 0.007326180063436283,\n",
       " 'heading': 0.0017971460132686482,\n",
       " 'ath': 0.002031640622476599,\n",
       " '65': 0.0037299500649220613,\n",
       " 'acquisition': 0.001143403466385876,\n",
       " 'total': 0.003915349384047907,\n",
       " '500': 0.0030355101065238596,\n",
       " 'past': 0.005361722469493091,\n",
       " 'exit': 0.0009496062686933546,\n",
       " 'zone': 0.0010264791571113882,\n",
       " 'fantastic': 0.0003707986382516909,\n",
       " 'read': 0.0024683303079437472,\n",
       " 'oil': 0.0030781454900162143,\n",
       " 'tighten': 0.0001324280850898896,\n",
       " 'bbl': 9.560661752831054e-05,\n",
       " 'getting': 0.007870104198293293,\n",
       " 'closer': 0.0006304868831596695,\n",
       " 'greatest': 0.000271962067428505,\n",
       " 'yearly': 0.0007997364358111382,\n",
       " 'performance': 0.001352704439893799,\n",
       " 'did': 0.008145296219016673,\n",
       " '98': 0.0017906861066788974,\n",
       " 'fosl': 3.4883495584653845e-05,\n",
       " '195c7be0': 1.4857785156426639e-05,\n",
       " '5092': 1.4857785156426639e-05,\n",
       " '4f1c': 1.4857785156426639e-05,\n",
       " '9083': 1.4857785156426639e-05,\n",
       " '62f56f783cdf': 1.4857785156426639e-05,\n",
       " 'champion': 0.00010271251477703632,\n",
       " 'cashflow': 4.844929942313034e-05,\n",
       " 'highyield': 1.4857785156426639e-05,\n",
       " 'telecommunication': 4.5219346128254985e-06,\n",
       " 'pretty': 0.0029095419280237207,\n",
       " 'risky': 0.0004605913398492258,\n",
       " 'gamble': 0.0005374642282672592,\n",
       " 'either': 0.0020904257724433306,\n",
       " 'plummet': 0.0002105929548258732,\n",
       " 'rally': 0.004012893973553143,\n",
       " 'stronger': 0.0005600739013313867,\n",
       " 'apple': 0.008346845304616895,\n",
       " 'zssadiq': 6.459906589750712e-07,\n",
       " 'talking': 0.0017732443588865704,\n",
       " 'referring': 6.912100051033263e-05,\n",
       " 'intelsat': 3.875943953850427e-06,\n",
       " 'punish': 8.268680434880912e-05,\n",
       " 'seller': 0.00194895381812779,\n",
       " 'warehouse': 5.684717798980627e-05,\n",
       " 'sense': 0.001424409403040032,\n",
       " 'old': 0.002463808373330922,\n",
       " 'gather': 8.462477632573432e-05,\n",
       " 'dust': 0.0002797139553362058,\n",
       " 'pc': 0.00039405430197479344,\n",
       " 'gamers': 0.00013759601036169016,\n",
       " 'crypto': 0.0011304836532063747,\n",
       " 'miner': 0.00010917242136678703,\n",
       " 'gpu': 0.000843663800621443,\n",
       " 'enthusiast': 1.7441747792326922e-05,\n",
       " 'waiting': 0.004678910342956441,\n",
       " 'two': 0.0035607005122705927,\n",
       " 'only': 0.012277698464480204,\n",
       " 'medium': 0.0025865465985361854,\n",
       " 'decent': 0.0018914606494790085,\n",
       " 'pattern': 0.004219610984425165,\n",
       " 'mnk': 0.00010206652411806126,\n",
       " 'd857317a': 3.9405430197479344e-05,\n",
       " 'd94c': 3.9405430197479344e-05,\n",
       " '4373': 4.3927364810304844e-05,\n",
       " 'adc3': 3.9405430197479344e-05,\n",
       " '9cbe67b2f3fb': 3.9405430197479344e-05,\n",
       " 'five': 0.00047738709698257764,\n",
       " 'baba': 0.0003527108998003889,\n",
       " 'ahhhhhhhhhhhhhhhhhhhhh': 6.459906589750712e-07,\n",
       " 'raytheon': 0.00011369435597961254,\n",
       " 'industrials': 0.000199611113623297,\n",
       " 'military': 0.00019896512296432194,\n",
       " 'trending': 0.0012642037196142143,\n",
       " 'riiiiiiiiiich': 6.459906589750712e-07,\n",
       " 'sooooon': 7.105897248725784e-06,\n",
       " 'buuuuls': 6.459906589750712e-07,\n",
       " 'looooove': 2.583962635900285e-06,\n",
       " 'drunk': 0.00013372006640783974,\n",
       " 'doesn': 0.004054883366386522,\n",
       " 'through': 0.0039760725059915635,\n",
       " 'gapping': 0.0001841073378078953,\n",
       " '54': 0.0027629020484363797,\n",
       " '64': 0.0024470126161975697,\n",
       " 'warbey': 6.459906589750712e-07,\n",
       " 'parker': 0.0001324280850898896,\n",
       " '8b': 9.237666423343518e-05,\n",
       " 'prep': 6.52450565564822e-05,\n",
       " 'glass': 0.00019121323505662109,\n",
       " 'seen': 0.002476082195851448,\n",
       " 'focus': 0.0006841041078546004,\n",
       " 'fashion': 0.0001369500197027151,\n",
       " 'wrt': 1.033585054360114e-05,\n",
       " 'wearable': 6.847500985135755e-05,\n",
       " 'like': 0.033537251051349797,\n",
       " 'sbux': 0.0002241587586643497,\n",
       " 'paying': 0.0009857817455959587,\n",
       " 'full': 0.001930866079676488,\n",
       " 'sex': 0.00011046440268473718,\n",
       " 'change': 0.0033488155761267693,\n",
       " 'employee': 0.0007112357155315534,\n",
       " 'hit': 0.008085219087731991,\n",
       " 'bottom': 0.006263525429422291,\n",
       " 'line': 0.004561986033681953,\n",
       " 'recap': 0.0008675654550035207,\n",
       " '63': 0.002194430268538317,\n",
       " 'since': 0.01460326483679046,\n",
       " 'post': 0.005110432103151788,\n",
       " '62': 0.0025716888133797584,\n",
       " 'trade': 0.03201271309616863,\n",
       " 'included': 0.0002422464971156517,\n",
       " 'hsy': 3.294552360772863e-05,\n",
       " 'uri': 4.844929942313034e-05,\n",
       " 'sonc': 7.105897248725784e-06,\n",
       " 'dri': 4.586533678723006e-05,\n",
       " 'kmx': 3.682146756157906e-05,\n",
       " 'akam': 4.9095290082105414e-05,\n",
       " 'enterprise': 0.0008591675764368447,\n",
       " 'value': 0.0036711649149553296,\n",
       " 'v': 0.003481243661216659,\n",
       " 'cap': 0.0026169081595080134,\n",
       " 'difference': 0.0003882403860440178,\n",
       " 'actual': 0.00041924793767482123,\n",
       " 'asset': 0.0012306122053475108,\n",
       " 'spread': 0.0015846150864658496,\n",
       " 'way': 0.010639466153319423,\n",
       " 'undervalued': 0.0016272504699582043,\n",
       " 'million': 0.003981240431263364,\n",
       " 'added': 0.0035930000452193463,\n",
       " 'dont': 0.004045839497160871,\n",
       " 'become': 0.0010226032131575378,\n",
       " 'such': 0.0018843547522302828,\n",
       " 'monopoly': 0.0002105929548258732,\n",
       " 'dipping': 0.00019767314164637179,\n",
       " 'into': 0.01116142660577128,\n",
       " 'everything': 0.002775821861615881,\n",
       " 'airline': 0.0006104611727314423,\n",
       " 'possibility': 0.0003029696190593084,\n",
       " 'loss': 0.0050019056724439764,\n",
       " '14': 0.009572289584692605,\n",
       " '95': 0.002749336244597903,\n",
       " 'suggested': 0.00020736300153099786,\n",
       " 'chartmill': 0.0001459938889283661,\n",
       " 'analyzer': 0.00033591514266703704,\n",
       " 'amd': 0.014821609679524034,\n",
       " 'eb84b522': 0.000217698852074599,\n",
       " 'efcd': 0.000217698852074599,\n",
       " '4183': 0.00021834484273357407,\n",
       " '8ba7': 0.000217698852074599,\n",
       " 'de1f10d58338': 0.000217698852074599,\n",
       " 'resistance': 0.004570383912248629,\n",
       " 'len': 6.07231219436567e-05,\n",
       " '08': 0.01834225877093817,\n",
       " 'reversal': 0.0031769820608394004,\n",
       " 'progress': 0.00036563071297989033,\n",
       " 'grandtraversebay': 3.2299532948753562e-06,\n",
       " 've': 0.00435010109753813,\n",
       " 'recently': 0.000534880265631359,\n",
       " 'closed': 0.002165360688884439,\n",
       " 'list': 0.0021020536043048817,\n",
       " 'bought': 0.012355863334216188,\n",
       " 'same': 0.007810027067008611,\n",
       " 'used': 0.0011266077092525243,\n",
       " 'according': 0.001313945000355295,\n",
       " 'data': 0.006288073074463343,\n",
       " 'reported': 0.009141413815156233,\n",
       " 'finra': 0.0017887481347019722,\n",
       " 'clocked': 0.00045671539589537535,\n",
       " '58': 0.0025955904677618363,\n",
       " 'official': 0.0003049075910362336,\n",
       " 'came': 0.0010536107647883411,\n",
       " 'saying': 0.0025994664117156866,\n",
       " 'agree': 0.0009974095774575099,\n",
       " 'resume': 0.0003333311800311367,\n",
       " 'cover': 0.0037971330934554685,\n",
       " 'penis': 3.036156097182835e-05,\n",
       " 'putang': 6.459906589750712e-07,\n",
       " 'front': 0.0003682146756157906,\n",
       " 'leg': 0.0014541249733528853,\n",
       " 'would': 0.01447729665829032,\n",
       " 'some': 0.01965555778063449,\n",
       " 'am': 0.008609117512160773,\n",
       " 'watching': 0.003598813961150122,\n",
       " '78': 0.002197660221833192,\n",
       " '99': 0.002229959754781946,\n",
       " 'wonder': 0.0019373259862662385,\n",
       " 'valued': 0.0010490888301755157,\n",
       " '6th': 0.00025904225424900354,\n",
       " 'inning': 4.4573355469279915e-05,\n",
       " 'ge': 0.002403085251387265,\n",
       " 'b7127dd5': 0.00018475332846687036,\n",
       " 'bca3': 0.00018475332846687036,\n",
       " '4d9e': 0.00018475332846687036,\n",
       " '9c45': 0.00018927526307969587,\n",
       " 'f4fe38eb7902': 0.00018475332846687036,\n",
       " 'newtrader0126': 5.16792527180057e-06,\n",
       " 'higher': 0.01646307194397969,\n",
       " 'also': 0.0051143080471056385,\n",
       " 'shorted': 0.0019205302291328866,\n",
       " '165': 0.000906970885201,\n",
       " '175': 0.0013578723651655998,\n",
       " 'consolidation': 0.0013113610377193945,\n",
       " 'cautious': 0.0003333311800311367,\n",
       " 'stunned': 2.7131607676952992e-05,\n",
       " 'deeply': 5.9431140625706555e-05,\n",
       " 'disappointed': 0.00029521773115160754,\n",
       " 'close': 0.019063830337013327,\n",
       " '69': 0.0020645861460843276,\n",
       " 'ending': 0.0007842326599957365,\n",
       " '430': 0.00013953398233861538,\n",
       " 'killed': 0.000788754594608562,\n",
       " 'best': 0.006448924748548136,\n",
       " 'february': 0.0002422464971156517,\n",
       " '782': 3.4237504925678774e-05,\n",
       " 'funny': 0.0016291884419351297,\n",
       " 'thing': 0.008144004237698723,\n",
       " 'similar': 0.000734491379254656,\n",
       " 'story': 0.001714459208919839,\n",
       " 'different': 0.001006453446683161,\n",
       " 'crab': 2.519363570002778e-05,\n",
       " 'measured': 0.0003158894322388098,\n",
       " 'divergence': 0.0004999967700467052,\n",
       " 'really': 0.007291296567851629,\n",
       " 'momentum': 0.0021924922965613916,\n",
       " 'starting': 0.0020994696416689815,\n",
       " 'shi': 3.81134488795292e-05,\n",
       " '229': 0.0002060710202130477,\n",
       " 'venture': 0.0001931512070335463,\n",
       " 'tariff': 0.0052112066459519,\n",
       " 'increase': 0.0025729807946977086,\n",
       " 'profit': 0.010409493478724297,\n",
       " 'recession': 0.000671184294675099,\n",
       " 'come': 0.011937907377859316,\n",
       " 'keep': 0.009674356108810667,\n",
       " 'buying': 0.015391373440740047,\n",
       " 'pure': 0.0006027092848237414,\n",
       " 'beanscreen': 1.2919813179501424e-06,\n",
       " 'q3': 0.021574150037790455,\n",
       " 'min': 0.00276548601107228,\n",
       " 'indicating': 0.0002784219740182557,\n",
       " 'accumulation': 0.00047286516236975213,\n",
       " 'eod': 0.003331373828334442,\n",
       " 'could': 0.010475384525939754,\n",
       " 'pop': 0.004898547167007965,\n",
       " 'heavy': 0.0011078739801422472,\n",
       " '244': 0.00010465048675396154,\n",
       " 'apog': 4.5219346128254985e-06,\n",
       " 'acn': 4.5219346128254986e-05,\n",
       " 'camp': 4.0051420856454416e-05,\n",
       " 'gi': 6.52450565564822e-05,\n",
       " 'payx': 2.648561701797792e-05,\n",
       " 'fdx': 0.00010723444938986183,\n",
       " 'goo': 0.0001143403466385876,\n",
       " 'squeeze': 0.0036724568962732797,\n",
       " 'pullback': 0.0029347355637237486,\n",
       " '163': 0.00029327975917468234,\n",
       " 'upside': 0.003344293641513944,\n",
       " 'nvda': 0.0022732411289332756,\n",
       " 'safe': 0.0012855214113603917,\n",
       " 'yield': 0.0016278964606171794,\n",
       " 'div': 0.001423117421722082,\n",
       " '68': 0.002094947707056156,\n",
       " 'adding': 0.0019101943785892856,\n",
       " '51': 0.0028346070115826123,\n",
       " 'gladly': 5.8785149966731484e-05,\n",
       " 'irrationality': 1.550377581540171e-05,\n",
       " 'reign': 2.583962635900285e-05,\n",
       " 'possible': 0.002695719019902972,\n",
       " 'excess': 4.26353834923547e-05,\n",
       " 'gain': 0.007546462878146782,\n",
       " 'welcome': 0.0008662734736855705,\n",
       " 'gl': 0.001941847920879064,\n",
       " 'seeing': 0.0016550280682941325,\n",
       " 'jumping': 0.00045671539589537535,\n",
       " 'joy': 0.00017570945924121937,\n",
       " 'least': 0.0035665144282013683,\n",
       " 'given': 0.0019282821170405876,\n",
       " 'action': 0.004415346154094612,\n",
       " ...}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The most of words are not used more than 100,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---> set 'high_cut_off' : 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x7f32cd92c0f0>],\n",
       " <a list of 1 Text yticklabel objects>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f32cd8f9710>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(bow.values(),\n",
    "            notch=1,\n",
    "            vert=False,\n",
    "           )\n",
    "plt.title(\"Box plot of the number of token used\")\n",
    "plt.yticks([1], ['Token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In below three graphs, we can find that exponential decrease is fading after 'word used count '> 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## low = 100\n",
    "## low_cutoff = 100/len(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f32cd8f3940>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rge = plt.hist(bow.values(), bins=100, range=(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f32cd6950b8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rge = plt.hist(bow.values(), bins=100, range=(10, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f32cd6d0400>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rge = plt.hist(bow.values(), bins=100, range=(100, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of selected token :6784,  which is used between 100~100000 times\n",
      "This is 4.90% amount of words in original bow\n",
      "\n",
      "Words which was used more than 100 words start from word like below\n",
      "---> bullflag, stryker, fab, levermann, coil, stability, lotta, denied, rocketing, boner, frontier, 9, marketplace, gig, crater, modern, alb, prosper, disappeared, richest\n",
      "\n",
      "outlier words(14.84% of selected_bow) start from word like below\n",
      "---> health, picked, overweight, tran, alerted, whale, utm, setupalert, maxgain, daystoexpire, sincealerted ... etc\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f32cd6d7b70>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "low = 100\n",
    "high = 100000\n",
    "selected_bow = { w:c for w, c in bow.items() if low<= c <=high}\n",
    "sorted_word = [k for k, v in sorted(selected_bow.items(), key=lambda kv:kv[1])]\n",
    "\n",
    "r = plt.boxplot(selected_bow.values(),\n",
    "            notch=1,\n",
    "            vert=False,\n",
    "           )\n",
    "#plt.title()\n",
    "plt.yticks([1], ['Token'])\n",
    "\n",
    "print(f\"The number of selected token :{len(selected_bow)}, \"\n",
    "      f\" which is used between {low}~{high} times\")\n",
    "print(f\"This is {len(selected_bow)*100/len(bow):4.2f}% amount of words in original bow\\n\")\n",
    "\n",
    "\n",
    "print(f\"Words which was used more than {low} words start from word like below\\n\"\n",
    "      f\"---> {', '.join(sorted_word[:20])}\\n\")\n",
    "\n",
    "      \n",
    "outlier_count = [count for count in r['fliers'][0].get_xdata()[-10:]]\n",
    "outlier_words = [ w for w, c in selected_bow.items() if c in outlier_count]\n",
    "print(f\"outlier words({len(r['fliers'][0].get_xdata())*100/len(selected_bow):4.2f}% of selected_bow) \"\n",
    "      f\"start from word like below\\n\"\n",
    "      f\"---> {', '.join(outlier_words)} ... etc\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So, using EDA, we drop 95% words in original vocab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'to', 'is', 'for', 'on', 'of', 'and', 'in', 'this', '39', 'it', 'at', 'will', 'up', 'are', 'you', 'that', 'be', 'short', '10']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6741"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Set the following variables:\n",
    "    freqs\n",
    "    low_cutoff\n",
    "    high_cutoff\n",
    "    K_most_common\n",
    "\"\"\"\n",
    "low = 100\n",
    "\n",
    "total = len(tokenized)\n",
    "# Dictionart that contains the Frequency of words appearing in messages.\n",
    "# The key is the token and the value is the frequency of that word in the corpus.\n",
    "freqs = { w:c/num_of_messages for w, c in bow.items()}\n",
    "\n",
    "# Float that is the frequency cutoff. Drop words with a frequency that is lower or equal to this number.\n",
    "low_cutoff = low/total\n",
    "\n",
    "# Integer that is the cut off for most common words. Drop words that are the `high_cutoff` most common words.\n",
    "high_cutoff = 20\n",
    "\n",
    "# The k most common words in the corpus. Use `high_cutoff` as the k.\n",
    "K_most_common = [ w for w, f, in bow.most_common(high_cutoff)]\n",
    "\n",
    "\n",
    "filtered_words = [word for word in freqs if (freqs[word] > low_cutoff and word not in K_most_common)]\n",
    "print(K_most_common)\n",
    "len(filtered_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_20 = K_most_common = [ w for w, f, in bow.most_common(20)]\n",
    "common_30 = K_most_common = [ w for w, f, in bow.most_common(30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2018',\n",
       " 'buy',\n",
       " 'down',\n",
       " 'here',\n",
       " 'just',\n",
       " 'not',\n",
       " 'stock',\n",
       " 'today',\n",
       " 'what',\n",
       " 'with'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(common_30) - set(common_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Vocabulary by Removing Filtered Words\n",
    "Let's creat three variables that will help with our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set the following variables:\n",
    "    vocab\n",
    "    id2vocab\n",
    "    filtered\n",
    "\"\"\"\n",
    "\n",
    "# A dictionary for the `filtered_words`. The key is the word and value is an id that represents the word. \n",
    "vocab = { v:i for i, v in enumerate(filtered_words)}\n",
    "\n",
    "# Reverse of the `vocab` dictionary. The key is word id and value is the word. \n",
    "id2vocab = {i:v for i, v in vocab.items()}\n",
    "\n",
    "# tokenized with the words not in `filtered_words` removed.\n",
    "filtered = [[word for word in message if word in vocab] for message in tokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the classes\n",
    "Let's do a few last pre-processing steps. If we look at how our twits are labeled, we'll find that **50% of them are neutral.** This means that our network will be 50% accurate just by guessing 0 every single time. To help our network learn appropriately, we'll want to balance our classes.\n",
    "That is, make sure each of our different sentiment scores show up roughly as frequently in the data.\n",
    "\n",
    "What we can do here is go through each of our examples and **randomly drop twits with neutral sentiment**. What should be the probability we drop these twits if we want to get around 20% neutral twits starting at 50% neutral? We should also take this opportunity to remove messages with length 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced = {'messages': [], 'sentiments':[]}\n",
    "\n",
    "n_neutral = sum(1 for each in sentiments if each == 2)\n",
    "N_examples = len(sentiments)\n",
    "keep_prob = (N_examples - n_neutral)/4/n_neutral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3016022730997995"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced = {'messages': [], 'sentiments':[]}\n",
    "\n",
    "n_neutral = sum(1 for each in sentiments if each == 2)\n",
    "N_examples = len(sentiments)\n",
    "keep_prob = (N_examples - n_neutral)/4/n_neutral\n",
    "\n",
    "for idx, sentiment in enumerate(sentiments):\n",
    "    message = filtered[idx]\n",
    "    if len(message) == 0:\n",
    "        # skip this message because it has length zero\n",
    "        continue\n",
    "    \n",
    "    # 감정이 중립이 아니거나 or 30% 유지\n",
    "    elif sentiment != 2 or random.random() < keep_prob:\n",
    "        balanced['messages'].append(message)\n",
    "        balanced['sentiments'].append(sentiment) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did it correctly, you should see the following result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19358702573420927"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neutral = sum(1 for each in balanced['sentiments'] if each == 2)\n",
    "N_examples = len(balanced['sentiments'])\n",
    "n_neutral/N_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's convert our tokens into integer ids which we can pass to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = [[vocab[word] for word in message] for message in balanced['messages']]\n",
    "sentiments = balanced['sentiments']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "Now we have our vocabulary which means we can transform our tokens into ids, which are then passed to our network. So, let's define the network now!\n",
    "\n",
    "Here is a nice diagram showing the network we'd like to build: \n",
    "\n",
    "#### Embed -> RNN -> Dense -> Softmax\n",
    "### Implement the text classifier\n",
    "Before we build text classifier, if you remember from the other network that you built in  \"Sentiment Analysis with an RNN\"  exercise  - which there, the network called \" SentimentRNN\", here we named it \"TextClassifer\" - consists of three main parts: 1) init function `__init__` 2) forward pass `forward`  3) hidden state `init_hidden`. \n",
    "\n",
    "This network is pretty similar to the network you built expect in the  `forward` pass, we use softmax instead of sigmoid. The reason we are not using sigmoid is that the output of NN is not a binary. In our network, sentiment scores have 5 possible outcomes. We are looking for an outcome with the highest probability thus softmax is a better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I prefer 'batch_first' shape !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, lstm_size, output_size, lstm_layers=1, dropout=0.1, pad_idx=0):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            vocab_size : The vocabulary size.\n",
    "            embed_size : The embedding layer size.\n",
    "            lstm_size : The LSTM layer size.\n",
    "            output_size : The output size.\n",
    "            lstm_layers : The number of LSTM layers.\n",
    "            dropout : The dropout probability.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.output_size = output_size\n",
    "        self.lstm_layers = lstm_layers\n",
    "        self.dropout = dropout\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "        # Setup embedding layer\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size,\n",
    "                                      embedding_dim=embed_size,\n",
    "                                      padding_idx=pad_idx\n",
    "                                     )\n",
    "        \n",
    "        # Setup additional layers\n",
    "        self.lstm = nn.LSTM(input_size=embed_size,\n",
    "                            hidden_size=lstm_size,\n",
    "                            num_layers=lstm_layers,\n",
    "                            batch_first=True,\n",
    "                            dropout=dropout\n",
    "                           )\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.linear = nn.Linear(lstm_size, output_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    " \n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\" \n",
    "        Initializes hidden state\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            batch_size : The size of batches.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            hidden_state\n",
    "            \n",
    "        \"\"\"\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        return (torch.zeros(self.lstm_layers, batch_size, self.lstm_size),\n",
    "                torch.zeros(self.lstm_layers, batch_size, self.lstm_size))\n",
    "\n",
    "\n",
    "    def forward(self, nn_input, hidden_state, lengths):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on nn_input.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            nn_input : The batch of input to the NN.\n",
    "            hidden_state : The LSTM hidden state.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            logps: log softmax output\n",
    "            hidden_state: The new hidden state.\n",
    "\n",
    "        \"\"\"\n",
    "        embeddings = self.embedding(nn_input)\n",
    "        pad_pack = pack_padded_sequence(embeddings,\n",
    "                                        lengths,\n",
    "                                        batch_first=True,\n",
    "                                       )\n",
    "        pad_pack_lstm = self.lstm(pad_pack)\n",
    "        seq, (ht, ct) = pad_pack_lstm\n",
    "        lstm_output = self.dropout(ht[-1])\n",
    "        \n",
    "        fc_output = self.linear(lstm_output) # batch_size, hidden_size\n",
    "        log_softmax = self.log_softmax(fc_output)\n",
    "        \n",
    "        return log_softmax, ht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7469, -1.4661, -1.6829, -2.0134, -1.2892],\n",
      "        [-1.7288, -1.4654, -1.7396, -1.9946, -1.2735],\n",
      "        [-1.7549, -1.4393, -1.7346, -1.8903, -1.3375],\n",
      "        [-1.7386, -1.4609, -1.7143, -1.9963, -1.2864],\n",
      "        [-1.7306, -1.4625, -1.7160, -2.0102, -1.2822]])\n"
     ]
    }
   ],
   "source": [
    "model = TextClassifier(len(vocab), 10, 6, 5, dropout=0.1, lstm_layers=2)\n",
    "model.embedding.weight.data.uniform_(-1, 1)\n",
    "input = torch.randint(0, 1000, (5, 4), dtype=torch.int64)\n",
    "hidden = model.init_hidden(4)\n",
    "\n",
    "logps, _ = model.forward(input, hidden, torch.LongTensor([4, 4, 4, 4, 4]))\n",
    "print(logps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### DataLoaders and Batching\n",
    "Now we should build a generator that we can use to loop through our data. It'll be more efficient if we can pass our sequences in as batches. Our input tensors should look like `(sequence_length, batch_size)`. So if our sequences are 40 tokens long and we pass in 25 sequences, then we'd have an input size of `(40, 25)`.\n",
    "\n",
    "If we set our sequence length to 40, what do we do with messages that are more or less than 40 tokens? For messages with fewer than 40 tokens, we will pad the empty spots with zeros. We should be sure to **left** pad so that the RNN starts from nothing before going through the data. If the message has 20 tokens, then the first 20 spots of our 40 long sequence will be 0. If a message has more than 40 tokens, we'll just keep the first 40 tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# padding left zeros is not best choice to deal with different length of sequences in type of RNN, If I want to take advantage of cuDNN for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(messages, labels, sequence_length=30, batch_size=32, shuffle=False, pad_idx=0):\n",
    "    \"\"\" \n",
    "    Build a dataloader.\n",
    "    \"\"\"\n",
    "    \n",
    "    if shuffle:\n",
    "        indices = list(range(len(messages)))\n",
    "        random.shuffle(indices)\n",
    "        messages = [messages[idx] for idx in indices]\n",
    "        labels = [labels[idx] for idx in indices]\n",
    "\n",
    "    total_sequences = len(messages)\n",
    "\n",
    "    for ii in range(0, total_sequences, batch_size):\n",
    "        batch_messages = messages[ii: ii+batch_size]\n",
    "        batch_messages = [m[:sequence_length] for m in batch_messages]\n",
    "        \n",
    "        input_lengths = torch.Tensor([len(t) for t in batch_messages])\n",
    "        input_lengths, sorted_idx = input_lengths.sort(0, descending=True)\n",
    "        \n",
    "        batch = [ torch.LongTensor(batch_messages[i]) for i in sorted_idx]\n",
    "        batch = pad_sequence(batch,\n",
    "                             batch_first=True,\n",
    "                             padding_value=pad_idx\n",
    "                            )\n",
    "        \n",
    "        label_tensor = labels[ii: ii+len(batch_messages)]\n",
    "        label_tensor = [label_tensor[idx] for idx in sorted_idx ]\n",
    "            \n",
    "        label_tensor = torch.tensor(label_tensor)\n",
    "        \n",
    "        yield batch, label_tensor, input_lengths.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and  Validation\n",
    "With our data in nice shape, we'll split it into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\"\"\"\n",
    "Split data into training and validation datasets. Use an appropriate split size.\n",
    "The features are the `token_ids` and the labels are the `sentiments`.\n",
    "\"\"\"   \n",
    "\n",
    "split_fraction = 0.3\n",
    "\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(token_ids,\n",
    "                                                                              sentiments,\n",
    "                                                                              test_size=split_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721156, 721156)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_features), len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309068, 309068)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_features), len(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_batch, labels, lengths = next(iter(dataloader(train_features, train_labels, sequence_length=20, batch_size=64)))\n",
    "model = TextClassifier(len(vocab)+1, 200, 128, 5, dropout=0.)\n",
    "hidden = model.init_hidden(64)\n",
    "logps, hidden = model.forward(text_batch, hidden, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "It's time to train the neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassifier(\n",
       "  (embedding): Embedding(6742, 1024, padding_idx=0)\n",
       "  (lstm): LSTM(1024, 512, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (dropout): Dropout(p=0.2)\n",
       "  (linear): Linear(in_features=512, out_features=5, bias=True)\n",
       "  (log_softmax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TextClassifier(len(vocab)+1, 1024, 512, 5, lstm_layers=2, dropout=0.2)\n",
    "model.embedding.weight.data.uniform_(-1, 1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# low=100, high limt word = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "[Epoc: 1/2] avg val_loss:0.00199 | validation_acc:59.00%\n",
      "[Epoc: 1/2] avg val_loss:0.00178 | validation_acc:63.00%\n",
      "[Epoc: 1/2] avg val_loss:0.00169 | validation_acc:66.00%\n",
      "[Epoc: 1/2] avg val_loss:0.00164 | validation_acc:67.00%\n",
      "[Epoc: 1/2] avg val_loss:0.00159 | validation_acc:68.00%\n",
      "[Epoc: 1/2] avg val_loss:0.00156 | validation_acc:68.00%\n",
      "[Epoc: 1/2] avg val_loss:0.00154 | validation_acc:69.00%\n",
      "[Epoc: 1/2] avg val_loss:0.00152 | validation_acc:69.00%\n",
      "[Epoc: 1/2] avg val_loss:0.00150 | validation_acc:70.00%\n",
      "[Epoc: 1/2] avg val_loss:0.00149 | validation_acc:70.00%\n",
      "[Epoc: 1/2] avg val_loss:0.00148 | validation_acc:70.00%\n",
      "[Epoc: 1/2] avg val_loss:0.00146 | validation_acc:70.00%\n",
      "[Epoc: 1/2] avg val_loss:0.00146 | validation_acc:70.00%\n",
      "[Epoc: 1/2] avg val_loss:0.00145 | validation_acc:71.00%\n",
      "Starting epoch 2\n",
      "[Epoc: 2/2] avg val_loss:0.00145 | validation_acc:71.00%\n",
      "[Epoc: 2/2] avg val_loss:0.00145 | validation_acc:71.00%\n",
      "[Epoc: 2/2] avg val_loss:0.00145 | validation_acc:71.00%\n",
      "[Epoc: 2/2] avg val_loss:0.00144 | validation_acc:71.00%\n",
      "[Epoc: 2/2] avg val_loss:0.00144 | validation_acc:71.00%\n",
      "[Epoc: 2/2] avg val_loss:0.00143 | validation_acc:71.00%\n",
      "[Epoc: 2/2] avg val_loss:0.00143 | validation_acc:71.00%\n",
      "[Epoc: 2/2] avg val_loss:0.00142 | validation_acc:71.00%\n",
      "[Epoc: 2/2] avg val_loss:0.00142 | validation_acc:71.00%\n",
      "[Epoc: 2/2] avg val_loss:0.00142 | validation_acc:71.00%\n",
      "[Epoc: 2/2] avg val_loss:0.00142 | validation_acc:71.00%\n",
      "[Epoc: 2/2] avg val_loss:0.00142 | validation_acc:71.00%\n",
      "[Epoc: 2/2] avg val_loss:0.00141 | validation_acc:71.00%\n",
      "[Epoc: 2/2] avg val_loss:0.00141 | validation_acc:72.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Train your model with dropout. Make sure to clip your gradients.\n",
    "Print the training loss, validation loss, and validation accuracy for every 100 steps.\n",
    "\"\"\"\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 512\n",
    "learning_rate = 1e-3\n",
    "max_grad_norm = 5\n",
    "valid_data_size = len(valid_labels)\n",
    "\n",
    "print_every = 100\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Starting epoch {}'.format(epoch + 1))\n",
    "    \n",
    "    steps = 0\n",
    "    for text_batch, labels, lengths in dataloader(\n",
    "            train_features, train_labels, batch_size=batch_size, sequence_length=20, shuffle=True):\n",
    "        steps += 1\n",
    "        hidden = model.init_hidden(labels.shape[0])\n",
    "        \n",
    "        # Set Device\n",
    "        text_batch, labels, lengths = text_batch.to(device), labels.to(device), lengths.to(device)\n",
    "        for each in hidden:\n",
    "            each.to(device)\n",
    "        \n",
    "        # Train Model\n",
    "        optimizer.zero_grad()\n",
    "        model_output, ht = model(text_batch, hidden, lengths)\n",
    "        \n",
    "        loss = criterion(model_output, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_grad_norm)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            model.eval()\n",
    "            \n",
    "            corrects, total_loss = 0, 0\n",
    "            # TODO Implement: Print metrics\n",
    "            for text_batch, labels, lengths in dataloader(valid_features,\n",
    "                                                          valid_labels,\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          sequence_length=20):\n",
    "                \n",
    "                text_batch, labels, lengths = text_batch.to(device), labels.to(device), lengths.to(device)\n",
    "                hidden = model.init_hidden(labels.shape[0])\n",
    "                for each in hidden:\n",
    "                    each.to(device)\n",
    "                \n",
    "                model_output, ht = model(text_batch, hidden, lengths)\n",
    "                val_loss = criterion(model_output, labels)\n",
    "                total_loss += val_loss.item()\n",
    "                corrects += (model_output.max(1)[1].view(labels.size()).data == labels.data).sum()\n",
    "                \n",
    "            model.train()\n",
    "            val_accuracy = 100.0 * corrects / valid_data_size\n",
    "            print(f\"[Epoc: {epoch+1}/{epochs}] avg val_loss:{total_loss/valid_data_size:5.5f} | validation_acc:{val_accuracy:5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can get good performance using only 5% words of original vocab !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "### Prediction \n",
    "Okay, now that you have a trained model, try it on some new twits and see if it works appropriately. Remember that for any new text, you'll need to preprocess it first before passing it to the network. Implement the `predict` function to generate the prediction vector from a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model, vocab):\n",
    "    \"\"\" \n",
    "    Make a prediction on a single sentence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        text : The string to make a prediction on.\n",
    "        model : The model to use for making the prediction.\n",
    "        vocab : Dictionary for word to word ids. The key is the word and the value is the word id.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        pred : Prediction vector\n",
    "    \"\"\"    \n",
    "    \n",
    "    # TODO Implement\n",
    "    \n",
    "    tokens = preprocess(text)\n",
    "    \n",
    "    # Filter non-vocab words\n",
    "    tokens = [ token for token in tokens if token in vocab]\n",
    "    # Convert words to ids\n",
    "    tokens = [ vocab[token] for token in tokens]\n",
    "        \n",
    "    # Adding a batch dimension\n",
    "    text_input = torch.LongTensor(tokens).unsqueeze(0)\n",
    "    print(text_input.shape)\n",
    "    # Get the NN output\n",
    "    hidden = model.init_hidden(1)\n",
    "    logps, _ = model(text_input, hidden, [len(tokens)])\n",
    "    # Take the exponent of the NN output to get a range of 0 to 1 for each label.\n",
    "    pred = torch.exp(logps)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0004,  0.0176,  0.0084,  0.8988,  0.0748]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Google is working on self driving cars, I'm bullish on $goog\"\n",
    "model.eval()\n",
    "model.to(\"cpu\")\n",
    "predict(text, model, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions: What is the prediction of the model? What is the uncertainty of the prediction?\n",
    "\n",
    "My model give the highest score to 'positive'(90%) label. The next highest labels are 'very positive'(8%) and 'negative'(2%). I think it is reasonable for my model to give '8%' to 'positive'. but I'm not sure why my model output the thirds highest score to 'negative'. I guess my model is mindful of the possibility that twits is irony case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a trained model and we can make predictions. We can use this model to track the sentiments of various stocks by predicting the sentiments of twits as they are coming in. Now we have a stream of twits. For each of those twits, pull out the stocks mentioned in them and keep track of the sentiments. Remember that in the twits, ticker symbols are encoded with a dollar sign as the first character, all caps, and 2-4 letters, like $AAPL. Ideally, you'd want to track the sentiments of the stocks in your universe and use this as a signal in your larger model(s).\n",
    "\n",
    "## Testing\n",
    "### Load the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('..', '..', 'data', 'project_6_stocktwits', 'test_twits.json'), 'r') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twit Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_body': '$JWN has moved -1.69% on 10-31. Check out the movement and peers at  https://dividendbot.com?s=JWN',\n",
       " 'timestamp': '2018-11-01T00:00:05Z'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def twit_stream():\n",
    "    for twit in test_data['data']:\n",
    "        yield twit\n",
    "\n",
    "next(twit_stream())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `prediction` function, let's apply it to a stream of twits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_twits(stream, model, vocab, universe):\n",
    "    \"\"\" \n",
    "    Given a stream of twits and a universe of tickers, return sentiment scores for tickers in the universe.\n",
    "    \"\"\"\n",
    "    for twit in stream:\n",
    "\n",
    "        # Get the message text\n",
    "        text = twit['message_body']\n",
    "        symbols = re.findall('\\$[A-Z]{2,4}', text)\n",
    "        score = predict(text, model, vocab)\n",
    "\n",
    "        for symbol in symbols:\n",
    "            if symbol in universe:\n",
    "                yield {'symbol': symbol, 'score': score, 'timestamp': twit['timestamp']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8])\n",
      "torch.Size([1, 14])\n",
      "torch.Size([1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'symbol': '$AAPL',\n",
       " 'score': tensor([[ 0.1407,  0.0095,  0.0218,  0.0290,  0.7991]]),\n",
       " 'timestamp': '2018-11-01T00:00:18Z'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universe = {'$BBRY', '$AAPL', '$AMZN', '$BABA', '$YHOO', '$LQMT', '$FB', '$GOOG', '$BBBY', '$JNUG', '$SBUX', '$MU'}\n",
    "score_stream = score_twits(twit_stream(), model, vocab, universe)\n",
    "\n",
    "next(score_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. You have successfully built a model for sentiment analysis! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Now that you're done with the project, it's time to submit it. Click the submit button in the bottom right. One of our reviewers will give you feedback on your project with a pass or not passed grade. You can continue to the next section while you wait for feedback."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
